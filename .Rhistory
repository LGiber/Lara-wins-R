shiny::runApp()
#install the necessary packages
install.packages("twitteR")
install.packages("wordcloud")
install.packages("tm")
library("twitteR")
library("wordcloud")
library("tm")
download.file(url="http://curl.haxx.se/ca/cacert.pem ", destfile="cacert.pem")
consumer_key <- 'TrviJZ5dHCmvHFEReiNa18RPX'
consumer_secret <- '1jMvdshbHXs8TSl9q3lKV9QhOkwEbGgfResJymyVyjlLk6DwTH'
access_token <- '213995172-Un1yzZGj8Geq693JTGLOGvsRHNdtsnNLeIMnCyVK'
access_secret <- 'PfwivqpYz7tXGHnPhn9Y7KPDUIXGJ0bBtOMqYDtQfIM7T'
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
tweets_Obama = searchTwitter(“@BarackObama”,n=1000,cainfo=”cacert.pem”)
tweets_Obama = searchTwitter(@BarackObama,n=1000,cainfo=”cacert.pem”)
tweets_Obama = searchTwitter("@BarackObama",n=1000,cainfo="cacert.pem")
tweets_Obama = searchTwitter("@BarackObama",n=1500)
length(tweets_Obama)
tweets_Cameron = searchTwitter("@David_Cameron",n=1500)
length(tweets_Cameron)
tweets.text.Obama = laply(tweets_Obama, function(t)t$getText())
library(ROAuth)
library("ROAuth")
install.packages("ROAuth")
tweets.text.Obama = saply(tweets_Obama, function(t)t$getText())
tweets.text.Obama = sapply(tweets_Obama, function(t)t$getText())
tweets.text.Cameron = sapply(tweets_Cameron, function(t)t$getText())
text_corpus_Obama <- Corpus(VectorSource(tweets.text.Obama))
text_corpus_Cameron <- Corpus(VectorSource(tweets.text.Cameron))
text_corpus_Obama <- tm_map(text_corpus_Obama, content_transformer(tolower))
text_corpus_Obama <- tm_map(text_corpus_Obama, removePunctuation)
text_corpus_Obama <- tm_map(text_corpus_Obama, function(x)removeWords(x,stopwords()))
text_corpus_Cameron <- tm_map(text_corpus_Cameron, content_transformer(tolower))
text_corpus_Cameron <- tm_map(text_corpus_Cameron, removePunctuation)
text_corpus_Cameron <- tm_map(text_corpus_Cameron, function(x)removeWords(x,stopwords()))
library(RColorBrewer)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(text_corpus_Obama,min.freq=2,max.words=100, random.order=T, colors=pal2)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(text_corpus_Obama,min.freq=2,max.words=100, random.order=T, colors=pal2)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(text_corpus_Obama,min.freq=2,max.words=100, random.order=T, colors=pal2)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(text_corpus_Cameron,min.freq=2,max.words=100, random.order=T, colors=pal2)
pos = scan(‘positive-words.txt’, what=’character’, comment.char=';’)
pos = scan('positive-words.txt', what='character', comment.char=';')
pos = scan('positive-words.txt', what='character', comment.char=';')
neg = scan('negative-words.txt', what='character', comment.char=';')
source('sentiment.r')
pos = scan('C:/Users/home/Desktop/sentiment.r/positive-words.txt', what='character', comment.char=';')
neg = scan('C:/Users/home/Desktop/sentiment.r/negative-words.txt', what='character', comment.char=';')
source('C:/Users/home/Desktop/sentiment.r')
install.packages("stringr")
install.packages("stringr")
install.packages("stringr")
library("stringr")
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
score.sentiment = function(tweets.text.Obama, pos.words, neg.words, .progress='none')
score.sentiment = function(tweets.text.Obama, pos.words, neg.words)
score.sentiment = function(tweets.text.Obama, pos.words, neg.words){
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}
library(plyr)
library(stringr)
scores = score.sentiment(tweets.text.Obama, pos, neg, .progress='text')
# add variables to data frame
scores$very.pos = as.numeric(scores$score >= 2)
scores$very.neg = as.numeric(scores$score <= -2)
# how many very positives and very negatives
numpos = sum(scores$very.pos)
numneg = sum(scores$very.neg)
# global score
global_score = round( 100 * numpos / (numpos + numneg) )
scores = laply(sentences,
function(sentence, pos.words, neg.words)
{
# remove punctuation
sentence = gsub("[[:punct:]]", "", sentence)
# remove control characters
sentence = gsub("[[:cntrl:]]", "", sentence)
# remove digits?
sentence = gsub('\\d+', '', sentence)
# define error handling function when trying tolower
tryTolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
sentence = sapply(sentence, tryTolower)
# split sentence into words with str_split (stringr package)
word.list = str_split(sentence, "\\s+")
words = unlist(word.list)
# compare words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# final score
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
# data frame with scores for each sentence
scores.df = data.frame(text=sentences, score=scores)
return(scores.df)
}
scores = laply(tweets_Obama,
function(tweets_Obama, pos.words, neg.words)
{
# remove punctuation
sentence = gsub("[[:punct:]]", "", tweets_Obama)
# remove control characters
sentence = gsub("[[:cntrl:]]", "", tweets_Obama)
# remove digits?
sentence = gsub('\\d+', '', tweets_Obama)
# define error handling function when trying tolower
tryTolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
tweets_Obama = sapply(tweets_Obama, tryTolower)
# split sentence into words with str_split (stringr package)
word.list = str_split(tweets_Obama, "\\s+")
words = unlist(word.list)
# compare words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# final score
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
# data frame with scores for each sentence
scores.df = data.frame(text=tweets_Obama, score=scores)
return(scores.df)
}
scores = score.sentiment(tweets.text.Obama, pos, neg, .progress='text')
scores$very.pos = as.numeric(scores$score >= 2)
scores$very.neg = as.numeric(scores$score <= -2)
scores = score.sentiment(tweets.text.Obama, pos, neg, .progress='text')
scores = score.sentiment(tweets.text.Obama, pos, neg, .progress='text')
numpos = sum(scores$very.pos)
numpos = sum(scores$pos)
numneg = sum(scores$neg)
ggplot(scores, aes(x=Obama, y=score)) +
geom_boxplot(aes(fill=drink)) +
scale_fill_manual(values=cols) +
geom_jitter(colour="gray40",
position=position_jitter(width=0.2), alpha=0.3) +
opts(title = "Boxplot - Obama's Sentiment Scores")
install.packages("plyr")
install.packages("plyr")
library(plyr)
source('C:/Users/home/Desktop/sentiment.r/sentiment.r')
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
table(analysis$score)
source('C:/Users/home/Desktop/sentiment.r/sentiment.r')
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
pos = scan('C:/Users/home/Desktop/sentiment.r/positive-words.txt', what='character', comment.char=';')
neg = scan('C:/Users/home/Desktop/sentiment.r/negative-words.txt', what='character', comment.char=';')
source('C:/Users/home/Desktop/sentiment.r/sentiment.r')
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words, exc.words)
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words, exc.words)
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
source('C:/Users/home/Desktop/sentiment.r/sentiment.r')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Obama, pos, neg)
table(analysis$score)
analysis = score.sentiment(tweets.text.Obama, pos, neg)
analysis = score.sentiment(text_corpus_Obama, pos, neg)
analysis = score.sentiment(tweets.text.Cameron, pos, neg)
analysis = score.sentiment(tweets.text.Cameron, pos.words, neg.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
pos.words = scan('C:/Users/home/Desktop/sentiment.r/positive-words.txt', what='character', comment.char=';')
neg.words = scan('C:/Users/home/Desktop/sentiment.r/negative-words.txt', what='character', comment.char=';')
analysis = score.sentiment(tweets.text.Cameron, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Cameron, pos.words, neg.words)
able(analysis$score)
table(analysis$score)
analysis = score.sentiment(tweets_Cameron, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Cameron, pos.words, neg.words)
analysis = score.sentiment(tweets.text.Obama, pos.words, neg.words)
usableTextObama=str_replace_all(tweets.text.Obama$text,"[^[:graph:]]", " ")
usableTextObama=str_replace_all(tweets_Obama$text,"[^[:graph:]]", " ")
analysis = score.sentiment(usableTextObama, pos.words, neg.words)
usableTextCameron=str_replace_all(tweets_Cameron$text,"[^[:graph:]]", " ")
usableTextCameron=str_replace_all(tweets.text.Cameron,"[^[:graph:]]", " ")
usableTextObama=str_replace_all(tweets.text.Obama,"[^[:graph:]]", " ")
analysis.Obama = score.sentiment(usableTextObama, pos.words, neg.words)
analysis.Cameron = score.sentiment(usableTextCameron, pos.words, neg.words)
table(analysis.Obama$score)
table(analysis.Cameron$Score)
table(analysis.Cameron$score)
library(ggplot)
instal.packages("ggplot")
install.packages("ggplot")
library(ggplot)
library("gplots", lib.loc="~/R/win-library/3.1")
barplot2(analysis.Obama, space = 1.5, axisnames = FALSE,
barplot2(analysis.Obama, space = 1.5, axisnames = FALSE,
sub = "barplot2(..., space = 1.5, axisnames = FALSE)")
library("ggplot2", lib.loc="~/R/win-library/3.1")
geom_boxplot(mapping = NULL, data = analysis.Obama, stat = "boxplot",
position = "dodge", outlier.colour = NULL, outlier.shape = NULL,
outlier.size = NULL, notch = FALSE, notchwidth = 0.5,
varwidth = FALSE, ...)
ggplot(scores, aes(x=1, y=score)) +
geom_boxplot(aes(fill=analysis.Obama)) +
scale_fill_manual(values=cols) +
geom_jitter(colour="gray40",
position=position_jitter(width=0.2), alpha=0.3) +
opts(title = "Boxplot - Drink's Sentiment Scores")
table(analysis.Obama$score)
table(analysis.Cameron$score)
install.packages("rmongodb")
library(devtools)
install_github(repo = "mongosoup/rmongodb")
install.packages("devtools")
library(devtools)
install_github(repo = "mongosoup/rmongodb")
library(rmongodb)
help("mongo.create")
mongo <- mongo.create()
mongo
mongo.is.connected(mongo)
mongo <- mongo.create()
mongo1 <- mongo.create()
mongo <- mongo.create("192.168.0.3")
mongo <- mongo.create("127.0.0.1")
drop mongo
mongo <- mongo.create()
mongo <- mongo.create("120.0.0.1:12345")
mongo <- mongo.create("120.0.0.1")
mongo
mongo.is.connected(mongo)
library(rmongodb)
m <- mongo.create()
ns <- "database.collection"
mongo.is.connected(m)
bson <- mongo.bson.from.JSON(mich_fav)
bson <- mongo.bson.from.JSON(tweets.text.Cameron)
tweetsObama <- favorites("tweets_Obama", n = 1000, max_id = NULL, since_id = NULL)
for (i in 1:length(tweetsObama))
{str<-tweetsObama[[i]]$getText(); mylist[[length(mylist)+1]]<-list(str)
}
json<-toJSON(mylist)
bson <- mongo.bson.from.JSON(json)
mongo.insert(m, ns, bson)
View(analysis.Cameron)
View(analysis.Cameron)
View(analysis.Cameron)
View(analysis.Obama)
save.image("C:/Users/home/Desktop/Final_Voronova/final.RData")
